require("dotenv").config();
const express = require("express");
const multer = require("multer");
const tf = require("@tensorflow/tfjs-node");
const fs = require("fs");
const path = require("path");
const cors = require("cors");

const app = express();
app.use(cors());

const PORT = process.env.PORT;
const MODEL_PATH = path.join(__dirname, "model");
const UPLOAD_DIR = path.join(__dirname, "uploads");

if (!fs.existsSync(UPLOAD_DIR)) {
  fs.mkdirSync(UPLOAD_DIR, { recursive: true });
}

const upload = multer({
  dest: UPLOAD_DIR,
  limits: { fileSize: 20 * 1024 * 1024 },
  fileFilter: (req, file, cb) => {
    if (file.mimetype.startsWith("image/")) {
      cb(null, true);
    } else {
      cb(new Error("Only image files are allowed!"), false);
    }
  },
});

let model;

(async () => {
  try {
    model = await tf.loadLayersModel(`file://${MODEL_PATH}/model.json`);
    console.log("âœ… Model loaded.");
    console.log("Input shape:", model.inputs[0].shape);
    console.log("Output shape:", model.outputs[0].shape);
  } catch (err) {
    console.error("âŒ Failed to load model:", err);
  }
})();

// Predict endpoint
app.post("/predict", upload.single("image"), async (req, res) => {
  if (!model) {
    return res
      .status(503)
      .json({ error: "Model not loaded yet. Please try again later." });
  }

  if (!req.file) {
    return res.status(400).json({ error: "No image uploaded" });
  }

  const imagePath = req.file.path;

  try {
    console.log(
      `ðŸ“¸ Processing image: ${req.file.originalname || req.file.filename}`
    );

    const buffer = fs.readFileSync(imagePath);

    const probabilities = await tf.tidy(() => {
      const tensor = tf.node
        .decodeImage(buffer, 3)
        .resizeNearestNeighbor([224, 224])
        .div(255.0)
        .expandDims();

      console.log("ðŸ“ Tensor shape:", tensor.shape);

      let prediction;
      try {
        prediction = model.predict(tensor);
      } catch (err) {
        throw new Error("Model prediction failed: " + err.message);
      }

      // Return the data from tidy so it can be used outside
      return prediction.dataSync();
    });

    // Convert to array for processing
    const probabilitiesArray = Array.from(probabilities);
    console.log("ðŸ“Š Raw probabilities:", probabilitiesArray);

    const classNames = ["Oidium Heveae", "Healthy", "Anthracnose", "Leaf Spot"];
    if (probabilitiesArray.length !== classNames.length) {
      throw new Error(
        `Expected ${classNames.length} output classes but got ${probabilitiesArray.length}`
      );
    }

    const predictions = probabilitiesArray.map((prob, index) => ({
      className: classNames[index],
      probability: prob,
    }));

    const topPrediction = predictions.reduce(
      (max, p) => (p.probability > max.probability ? p : max),
      { className: "", probability: 0 }
    );

    if (topPrediction.probability < 0.6) {
      console.warn("âš ï¸ Low confidence prediction:", topPrediction);
    }

    const response = {
      tfjsVersion: "1.7.4",
      tmVersion: "2.4.10",
      modelName: "tm-my-image-model",
      labels: classNames,
      predictions,
      topPrediction,
      imageSize: 224,
      timeStamp: new Date().toISOString(),
    };

    console.log("âœ… Top prediction:", topPrediction);

    try {
      await fs.promises.unlink(imagePath);
    } catch (err) {
      console.error("âŒ Error deleting uploaded file:", err);
    }

    return res.json(response);
  } catch (err) {
    console.error("âŒ Prediction error:", err.message);

    if (fs.existsSync(imagePath)) {
      try {
        await fs.promises.unlink(imagePath);
      } catch (err2) {
        console.error("âŒ Failed to delete file after error:", err2.message);
      }
    }

    return res.status(500).json({
      error: "Prediction failed",
      details: err.message,
    });
  }
});

app.get("/predict", (req, res) => {
  res.send(`âœ… Server is running and listening on port ${PORT}`);
});

app.listen(PORT, () => {
  console.log(`ðŸš€ Server running at http://localhost:${PORT}`);
});
